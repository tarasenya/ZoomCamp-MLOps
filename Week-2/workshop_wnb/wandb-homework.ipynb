{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad71015",
   "metadata": {},
   "source": [
    "**Q1. Install the Package**\n",
    "\n",
    "To get started with Weights & Biases you'll need to install the appropriate Python package.\n",
    "\n",
    "For this we recommend creating a separate Python environment, for example, you can use conda environments, and then install the package there with pip or conda.\n",
    "\n",
    "Once you installed the package, run the command wandb --version and check the output.\n",
    "\n",
    "What's the version that you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4bb2f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of W&B - 0.15.3\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(f'Version of W&B - {wandb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f4212",
   "metadata": {},
   "source": [
    "**Q2. Download and preprocess the data**\n",
    "\n",
    "We'll use the Green Taxi Trip Records dataset to predict the amount of tips for each trip.\n",
    "\n",
    "Download the data for January, February and March 2022 in parquet format from here.\n",
    "\n",
    "Use the script preprocess_data.py located in the folder homework-wandb to preprocess the data.\n",
    "\n",
    "The script will:\n",
    "\n",
    "- initialize a Weights & Biases run.\n",
    "- load the data from the folder <TAXI_DATA_FOLDER> (the folder where you have downloaded the data),\n",
    "- fit a DictVectorizer on the training set (January 2022 data),\n",
    "- save the preprocessed datasets and the DictVectorizer to your Weights & Biases dashboard as an artifact of type preprocessed_dataset.\n",
    "Your task is to download the datasets and then execute this command:\n",
    "\n",
    "```bash\n",
    "python preprocess_data.py \\\n",
    "  --wandb_project <WANDB_PROJECT_NAME> \\\n",
    "  --wandb_entity <WANDB_USERNAME> \\\n",
    "  --raw_data_path <TAXI_DATA_FOLDER> \\\n",
    "  --dest_path ./output\n",
    "```\n",
    "  \n",
    "_Tip_: go to 02-experiment-tracking/homework-wandb/ folder before executing the command and change the value of <WANDB_PROJECT_NAME> to the name of your Weights & Biases project, <WANDB_USERNAME> to your Weights & Biases username, and <TAXI_DATA_FOLDER> to the location where you saved the data.\n",
    "\n",
    "Once you navigate to the Files tab of your artifact on your Weights & Biases page, what's the size of the saved DictVectorizer file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3912f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = r'~/ZoomCamp-MLOps/Week-2/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87bc92",
   "metadata": {},
   "source": [
    "![title](screenshots/run_wandb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa19d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size equals 150.05859375 Kb\n"
     ]
    }
   ],
   "source": [
    "DICT_VECTORIZER_PATH = os.path.join(os.getcwd(),'output/dv.pkl')\n",
    "print(f\"Size equals {os.path.getsize(DICT_VECTORIZER_PATH)/1024} Kb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2b5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZoomCamp-MLOps",
   "language": "python",
   "name": "zoomcamp-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
